{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "pd.set_option(\"max_columns\", None)\n",
    "\n",
    "df = pd.read_csv('kddcup99.csv')\n",
    "df.drop(df[ (df.label != 'normal') & (df.label != 'smurf') ].index, inplace=True)\n",
    "df = df.iloc[:5000,:].append(df[df['label'] == 'smurf'].iloc[:5000,:], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.get_dummies(df['protocol_type'], prefix='protocol_type'), df], axis=1)\n",
    "df.drop('protocol_type', axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([pd.get_dummies(df['service'], prefix='service'), df], axis=1)\n",
    "df.drop('service', axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([pd.get_dummies(df['flag'], prefix='flag'), df], axis=1)\n",
    "df.drop('flag', axis=1, inplace=True)\n",
    "\n",
    "df['label'] = np.where(df['label'] == 'smurf', 1, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pollymorphism/miniconda3/lib/python3.7/site-packages/scipy/__init__.py:140: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.16.3)\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "df = pd.DataFrame(data=scaler.transform(df), columns=df.columns)\n",
    "df['label'] = np.where(df['label'] == 0, 0.0001, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0001\n",
       "1       0.0001\n",
       "2       0.0001\n",
       "3       0.0001\n",
       "4       0.0001\n",
       "5       0.0001\n",
       "6       0.0001\n",
       "7       0.0001\n",
       "8       0.0001\n",
       "9       0.0001\n",
       "10      0.0001\n",
       "11      0.0001\n",
       "12      0.0001\n",
       "13      0.0001\n",
       "14      0.0001\n",
       "15      0.0001\n",
       "16      0.0001\n",
       "17      0.0001\n",
       "18      0.0001\n",
       "19      0.0001\n",
       "20      0.0001\n",
       "21      0.0001\n",
       "22      0.0001\n",
       "23      0.0001\n",
       "24      0.0001\n",
       "25      0.0001\n",
       "26      0.0001\n",
       "27      0.0001\n",
       "28      0.0001\n",
       "29      0.0001\n",
       "         ...  \n",
       "9970    1.0000\n",
       "9971    1.0000\n",
       "9972    1.0000\n",
       "9973    1.0000\n",
       "9974    1.0000\n",
       "9975    1.0000\n",
       "9976    1.0000\n",
       "9977    1.0000\n",
       "9978    1.0000\n",
       "9979    1.0000\n",
       "9980    1.0000\n",
       "9981    1.0000\n",
       "9982    1.0000\n",
       "9983    1.0000\n",
       "9984    1.0000\n",
       "9985    1.0000\n",
       "9986    1.0000\n",
       "9987    1.0000\n",
       "9988    1.0000\n",
       "9989    1.0000\n",
       "9990    1.0000\n",
       "9991    1.0000\n",
       "9992    1.0000\n",
       "9993    1.0000\n",
       "9994    1.0000\n",
       "9995    1.0000\n",
       "9996    1.0000\n",
       "9997    1.0000\n",
       "9998    1.0000\n",
       "9999    1.0000\n",
       "Name: label, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.25, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750.375\n",
      "1250.125\n"
     ]
    }
   ],
   "source": [
    "print(train['label'].sum())\n",
    "print(test['label'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[27]:\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.random.randn(n_h, 1)*0.01\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.random.randn(n_y, 1)*0.01\n",
    "    \n",
    "    return W1, b1, W2, b2  \n",
    "\n",
    "def train_NN(x, y_r, DELTA, b1, b2, w1, w2, rand_state=42):\n",
    "    np.random.seed(42)\n",
    "    for i in range(1000):\n",
    "        y2 = sigmoid(w1.dot(x) + b1)\n",
    "        y_m = float(sigmoid(w2.dot(y2) + b2))\n",
    "        delta = float( np.absolute((y_r - y_m)/y_r))\n",
    "        \n",
    "        if delta <= DELTA:\n",
    "            return w1, w2, b1, b2, delta, y_m\n",
    "        else:\n",
    "            q3 = float( y_m * (1 - y_m) * (y_r - y_m) )\n",
    "            d2 = q3 * y2.reshape(1,-1)\n",
    "            w2 = w2 + d2\n",
    "\n",
    "          \n",
    "            q2 = y2 * (1 - y2) * (q3 * w2.reshape(-1, 1))\n",
    "            d = q2 * x.reshape(1, -1)\n",
    "            w1 = w1 + d\n",
    "    return w1, w2, b1, b2, delta, y_m\n",
    "    \n",
    "    \n",
    "    return output\n",
    "def train_NN_online(X, Y, DELTA = 0.1,\n",
    "                    hidden_l_size = 3, \n",
    "                    show_epochs_stat=False\n",
    "                   ):\n",
    "    all_time = time.time()\n",
    "    W1, b1, W2, b2 = initialize_parameters(X.shape[1], hidden_l_size, 1) \n",
    "\n",
    "    for epoch in range(1, 101):\n",
    "        deltas, y_ms = [], []\n",
    "        for x, y in zip(X, Y):\n",
    "            W1, W2, b1, b2, delta, y_m = train_NN(x.reshape(-1, 1), \n",
    "                                                  y, \n",
    "                                                  DELTA, \n",
    "                                                  b1=b1, b2=b2, \n",
    "                                                  w1=W1, w2=W2\n",
    "                                                 )\n",
    "            deltas.append(delta)\n",
    "            y_ms.append(y_m)\n",
    "        if ((epoch == 1) or (epoch % 50 == 0)) and show_epochs_stat:\n",
    "            print(f'\\n-----------------------Epoch {epoch}---------------------------')\n",
    "            print(pd.DataFrame({\n",
    "                'Y_r':Y, \n",
    "                'deltas':  deltas,\n",
    "                'Y_ms':y_ms      \n",
    "            }))\n",
    "            print('----------------------------------------------------------')   \n",
    "    print(f'counted for {time.time() - all_time}')\n",
    "    return W1, W2, b1, b2\n",
    "    \n",
    "\n",
    "def predict(x, w1, w2, b1, b2):\n",
    "    y1 = sigmoid(w1.dot(x) + b1)\n",
    "    \n",
    "    output = sigmoid(w2.dot(y1) + b2)\n",
    "    return float(output)\n",
    "def predict_online(X, w1, w2, b1, b2):\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        y_pred.append( predict(x.reshape(-1, 1), w1, w2, b1, b2) )\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------Epoch 1---------------------------\n",
      "         Y_r      deltas      Y_ms\n",
      "0     1.0000    0.097087  0.902913\n",
      "1     1.0000    0.097087  0.902913\n",
      "2     0.0001  103.926661  0.010493\n",
      "3     1.0000    0.097944  0.902056\n",
      "4     0.0001  104.111727  0.010511\n",
      "5     1.0000    0.098327  0.901673\n",
      "6     1.0000    0.098327  0.901673\n",
      "7     1.0000    0.098327  0.901673\n",
      "8     0.0001  105.130236  0.010613\n",
      "9     0.0001   75.024641  0.007602\n",
      "10    0.0001   60.777704  0.006178\n",
      "11    0.0001   53.201138  0.005420\n",
      "12    1.0000    0.098434  0.901566\n",
      "13    0.0001   89.679209  0.009068\n",
      "14    1.0000    0.099596  0.900404\n",
      "15    1.0000    0.099596  0.900404\n",
      "16    0.0001   75.968842  0.007697\n",
      "17    1.0000    0.099888  0.900112\n",
      "18    0.0001   62.202172  0.006320\n",
      "19    1.0000    0.098261  0.901739\n",
      "20    0.0001   53.587106  0.005459\n",
      "21    0.0001   38.758587  0.003976\n",
      "22    0.0001   43.591966  0.004459\n",
      "23    1.0000    0.099224  0.900776\n",
      "24    1.0000    0.099224  0.900776\n",
      "25    1.0000    0.099224  0.900776\n",
      "26    0.0001   31.593548  0.003259\n",
      "27    1.0000    0.098687  0.901313\n",
      "28    0.0001   80.627129  0.008163\n",
      "29    0.0001   10.477603  0.001148\n",
      "...      ...         ...       ...\n",
      "7470  1.0000    0.011800  0.988200\n",
      "7471  0.0001    0.229383  0.000077\n",
      "7472  0.0001    0.172676  0.000083\n",
      "7473  1.0000    0.011800  0.988200\n",
      "7474  0.0001    0.813151  0.000019\n",
      "7475  1.0000    0.011800  0.988200\n",
      "7476  0.0001    0.809104  0.000019\n",
      "7477  1.0000    0.011800  0.988200\n",
      "7478  1.0000    0.011800  0.988200\n",
      "7479  0.0001    0.089354  0.000109\n",
      "7480  1.0000    0.011800  0.988200\n",
      "7481  1.0000    0.011800  0.988200\n",
      "7482  0.0001    0.220849  0.000078\n",
      "7483  1.0000    0.011800  0.988200\n",
      "7484  0.0001    0.084012  0.000092\n",
      "7485  0.0001    0.801447  0.000020\n",
      "7486  1.0000    0.011799  0.988201\n",
      "7487  1.0000    0.011799  0.988201\n",
      "7488  1.0000    0.011799  0.988201\n",
      "7489  1.0000    0.011799  0.988201\n",
      "7490  1.0000    0.011830  0.988170\n",
      "7491  1.0000    0.011799  0.988201\n",
      "7492  0.0001    0.167046  0.000083\n",
      "7493  1.0000    0.011799  0.988201\n",
      "7494  0.0001    0.804250  0.000020\n",
      "7495  1.0000    0.011799  0.988201\n",
      "7496  1.0000    0.011799  0.988201\n",
      "7497  1.0000    0.011799  0.988201\n",
      "7498  1.0000    0.011799  0.988201\n",
      "7499  1.0000    0.011799  0.988201\n",
      "\n",
      "[7500 rows x 3 columns]\n",
      "----------------------------------------------------------\n",
      "\n",
      "-----------------------Epoch 50---------------------------\n",
      "         Y_r    deltas          Y_ms\n",
      "0     1.0000  0.002863  9.971375e-01\n",
      "1     1.0000  0.002863  9.971375e-01\n",
      "2     0.0001  0.957487  4.251266e-06\n",
      "3     1.0000  0.002863  9.971375e-01\n",
      "4     0.0001  0.973441  2.655944e-06\n",
      "5     1.0000  0.002863  9.971375e-01\n",
      "6     1.0000  0.002863  9.971375e-01\n",
      "7     1.0000  0.002863  9.971375e-01\n",
      "8     0.0001  0.962115  3.788486e-06\n",
      "9     0.0001  0.905284  9.471565e-06\n",
      "10    0.0001  0.804025  1.959746e-05\n",
      "11    0.0001  0.401918  5.980815e-05\n",
      "12    1.0000  0.002863  9.971375e-01\n",
      "13    0.0001  0.830744  1.692563e-05\n",
      "14    1.0000  0.002862  9.971375e-01\n",
      "15    1.0000  0.002862  9.971375e-01\n",
      "16    0.0001  0.506373  4.936275e-05\n",
      "17    1.0000  0.002862  9.971375e-01\n",
      "18    0.0001  0.401710  5.982901e-05\n",
      "19    1.0000  0.002862  9.971376e-01\n",
      "20    0.0001  0.423301  5.766994e-05\n",
      "21    0.0001  0.931393  6.860725e-06\n",
      "22    0.0001  0.176232  8.237684e-05\n",
      "23    1.0000  0.002862  9.971376e-01\n",
      "24    1.0000  0.002862  9.971376e-01\n",
      "25    1.0000  0.002862  9.971376e-01\n",
      "26    0.0001  0.966222  3.377844e-06\n",
      "27    1.0000  0.002862  9.971376e-01\n",
      "28    0.0001  0.991645  8.354984e-07\n",
      "29    0.0001  0.478509  5.214914e-05\n",
      "...      ...       ...           ...\n",
      "7470  1.0000  0.002912  9.970882e-01\n",
      "7471  0.0001  0.406980  5.930199e-05\n",
      "7472  0.0001  0.329947  6.700527e-05\n",
      "7473  1.0000  0.002912  9.970883e-01\n",
      "7474  0.0001  0.975787  2.421265e-06\n",
      "7475  1.0000  0.002912  9.970883e-01\n",
      "7476  0.0001  0.972702  2.729829e-06\n",
      "7477  1.0000  0.002912  9.970883e-01\n",
      "7478  1.0000  0.002912  9.970883e-01\n",
      "7479  0.0001  0.930761  6.923942e-06\n",
      "7480  1.0000  0.002912  9.970883e-01\n",
      "7481  1.0000  0.002912  9.970883e-01\n",
      "7482  0.0001  0.393310  6.066900e-05\n",
      "7483  1.0000  0.002912  9.970883e-01\n",
      "7484  0.0001  0.213198  7.868023e-05\n",
      "7485  0.0001  0.970648  2.935158e-06\n",
      "7486  1.0000  0.002912  9.970883e-01\n",
      "7487  1.0000  0.002912  9.970883e-01\n",
      "7488  1.0000  0.002912  9.970883e-01\n",
      "7489  1.0000  0.002912  9.970883e-01\n",
      "7490  1.0000  0.002920  9.970799e-01\n",
      "7491  1.0000  0.002912  9.970883e-01\n",
      "7492  0.0001  0.326236  6.737640e-05\n",
      "7493  1.0000  0.002912  9.970883e-01\n",
      "7494  0.0001  0.972468  2.753237e-06\n",
      "7495  1.0000  0.002912  9.970883e-01\n",
      "7496  1.0000  0.002912  9.970883e-01\n",
      "7497  1.0000  0.002912  9.970883e-01\n",
      "7498  1.0000  0.002912  9.970883e-01\n",
      "7499  1.0000  0.002912  9.970883e-01\n",
      "\n",
      "[7500 rows x 3 columns]\n",
      "----------------------------------------------------------\n",
      "\n",
      "-----------------------Epoch 100---------------------------\n",
      "         Y_r    deltas          Y_ms\n",
      "0     1.0000  0.002519  9.974814e-01\n",
      "1     1.0000  0.002519  9.974814e-01\n",
      "2     0.0001  0.951651  4.834940e-06\n",
      "3     1.0000  0.002519  9.974814e-01\n",
      "4     0.0001  0.970527  2.947345e-06\n",
      "5     1.0000  0.002519  9.974814e-01\n",
      "6     1.0000  0.002519  9.974814e-01\n",
      "7     1.0000  0.002519  9.974814e-01\n",
      "8     0.0001  0.957223  4.277705e-06\n",
      "9     0.0001  0.888395  1.116054e-05\n",
      "10    0.0001  0.760936  2.390639e-05\n",
      "11    0.0001  0.238736  7.612645e-05\n",
      "12    1.0000  0.002519  9.974815e-01\n",
      "13    0.0001  0.794655  2.053446e-05\n",
      "14    1.0000  0.002519  9.974815e-01\n",
      "15    1.0000  0.002519  9.974815e-01\n",
      "16    0.0001  0.372220  6.277800e-05\n",
      "17    1.0000  0.002518  9.974815e-01\n",
      "18    0.0001  0.239008  7.609925e-05\n",
      "19    1.0000  0.002518  9.974815e-01\n",
      "20    0.0001  0.265520  7.344801e-05\n",
      "21    0.0001  0.920086  7.991399e-06\n",
      "22    0.0001  0.052358  1.052358e-04\n",
      "23    1.0000  0.002518  9.974815e-01\n",
      "24    1.0000  0.002518  9.974815e-01\n",
      "25    1.0000  0.002518  9.974815e-01\n",
      "26    0.0001  0.962059  3.794081e-06\n",
      "27    1.0000  0.002518  9.974815e-01\n",
      "28    0.0001  0.992849  7.151480e-07\n",
      "29    0.0001  0.336613  6.633870e-05\n",
      "...      ...       ...           ...\n",
      "7470  1.0000  0.002546  9.974537e-01\n",
      "7471  0.0001  0.236866  7.631337e-05\n",
      "7472  0.0001  0.137235  8.627654e-05\n",
      "7473  1.0000  0.002546  9.974538e-01\n",
      "7474  0.0001  0.973266  2.673362e-06\n",
      "7475  1.0000  0.002546  9.974538e-01\n",
      "7476  0.0001  0.969491  3.050910e-06\n",
      "7477  1.0000  0.002546  9.974538e-01\n",
      "7478  1.0000  0.002546  9.974538e-01\n",
      "7479  0.0001  0.939530  6.046999e-06\n",
      "7480  1.0000  0.002546  9.974538e-01\n",
      "7481  1.0000  0.002546  9.974538e-01\n",
      "7482  0.0001  0.219861  7.801386e-05\n",
      "7483  1.0000  0.002546  9.974538e-01\n",
      "7484  0.0001  0.014948  1.014948e-04\n",
      "7485  0.0001  0.967066  3.293398e-06\n",
      "7486  1.0000  0.002546  9.974538e-01\n",
      "7487  1.0000  0.002546  9.974538e-01\n",
      "7488  1.0000  0.002546  9.974538e-01\n",
      "7489  1.0000  0.002546  9.974538e-01\n",
      "7490  1.0000  0.002554  9.974463e-01\n",
      "7491  1.0000  0.002546  9.974538e-01\n",
      "7492  0.0001  0.132636  8.673641e-05\n",
      "7493  1.0000  0.002546  9.974538e-01\n",
      "7494  0.0001  0.969314  3.068552e-06\n",
      "7495  1.0000  0.002546  9.974538e-01\n",
      "7496  1.0000  0.002546  9.974538e-01\n",
      "7497  1.0000  0.002546  9.974538e-01\n",
      "7498  1.0000  0.002546  9.974538e-01\n",
      "7499  1.0000  0.002546  9.974538e-01\n",
      "\n",
      "[7500 rows x 3 columns]\n",
      "----------------------------------------------------------\n",
      "counted for 6845.96789932251\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "w1, w2, b1, b2 = train_NN_online(train.iloc[:,:-1].values, train.iloc[:,-1].values, hidden_l_size = 7, show_epochs_stat=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      real      pred\n",
       "0      1.0  0.997325\n",
       "1      1.0  0.997454\n",
       "2      1.0  0.997454\n",
       "6      1.0  0.997454\n",
       "9      1.0  0.997454\n",
       "10     1.0  0.997454\n",
       "13     1.0  0.997454\n",
       "15     1.0  0.997454\n",
       "16     1.0  0.997454\n",
       "17     1.0  0.997454\n",
       "28     1.0  0.997454\n",
       "29     1.0  0.997454\n",
       "33     1.0  0.997454\n",
       "37     1.0  0.997454\n",
       "38     1.0  0.997454\n",
       "40     1.0  0.997454\n",
       "41     1.0  0.997454\n",
       "45     1.0  0.997454\n",
       "46     1.0  0.997454\n",
       "47     1.0  0.997454\n",
       "48     1.0  0.997454\n",
       "50     1.0  0.997454\n",
       "51     1.0  0.997454\n",
       "52     1.0  0.997454\n",
       "58     1.0  0.997454\n",
       "59     1.0  0.997454\n",
       "62     1.0  0.997454\n",
       "65     1.0  0.997454\n",
       "66     1.0  0.997454\n",
       "67     1.0  0.997454\n",
       "...    ...       ...\n",
       "2425   1.0  0.997454\n",
       "2426   1.0  0.997454\n",
       "2429   1.0  0.997446\n",
       "2430   1.0  0.997454\n",
       "2432   1.0  0.997454\n",
       "2437   1.0  0.997454\n",
       "2438   1.0  0.997454\n",
       "2440   1.0  0.997454\n",
       "2441   1.0  0.997454\n",
       "2442   1.0  0.997454\n",
       "2445   1.0  0.997454\n",
       "2448   1.0  0.997454\n",
       "2449   1.0  0.997454\n",
       "2454   1.0  0.997454\n",
       "2464   1.0  0.997454\n",
       "2466   1.0  0.997454\n",
       "2468   1.0  0.997454\n",
       "2469   1.0  0.997454\n",
       "2473   1.0  0.997454\n",
       "2474   1.0  0.997454\n",
       "2475   1.0  0.997454\n",
       "2478   1.0  0.997454\n",
       "2483   1.0  0.997454\n",
       "2485   1.0  0.997454\n",
       "2488   1.0  0.997454\n",
       "2490   1.0  0.997454\n",
       "2491   1.0  0.997454\n",
       "2494   1.0  0.997454\n",
       "2495   1.0  0.997454\n",
       "2497   1.0  0.997454\n",
       "\n",
       "[1250 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict_online(test.iloc[:,:-1].values, w1, w2, b1, b2)\n",
    "res = pd.DataFrame(data={\n",
    "    'real': test.iloc[:,-1].values,\n",
    "    'pred': pred\n",
    "})\n",
    "res[res['pred'] > 1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1  1250   0\n",
      "0    0 1250\n",
      "\n",
      "     1   0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "res['pred'] = np.where(res['pred'] > 1e-2, 1, 0)\n",
    "res['real'] = np.where(res['pred'] > 1e-2, 1, 0)\n",
    "a = confusion_matrix(res['real'], res['pred'])\n",
    "out = f\"\"\"\n",
    "1  {a[0][0]: >3} {a[0][1]: >3}\n",
    "0  {a[1][0]: >3} {a[1][1]: >3}\n",
    "\n",
    "     1   0\n",
    "\"\"\"\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
